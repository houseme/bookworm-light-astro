---
title: "Siumai æœ€ä½³å®è·µï¼šä»é›¶åˆ°ç²¾é€šçš„ Rust-AI å¼€å‘è“å›¾"
description: "æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ Siumai åœ¨å®é™…å¼€å‘ä¸­çš„æœ€ä½³å®è·µï¼Œè¦†ç›–ä»åŸºç¡€å¯¹è¯åˆ°å¤æ‚å·¥å…·è°ƒç”¨ã€æµå¼å¤„ç†ä¼˜åŒ–ä»¥åŠæœ¬åœ°æ¨¡å‹éƒ¨ç½²çš„åœºæ™¯ã€‚æˆ‘ä»¬å°†ç»“åˆç†è®ºåˆ†æä¸å®æˆ˜ä»£ç ï¼Œç”±æµ…å…¥æ·±åœ°å±•ç¤ºå¦‚ä½•åˆ©ç”¨ Siumai æ„å»ºé«˜æ•ˆã€å¥å£®çš„ AI åº”ç”¨ï¼ŒåŠ©ä½ æˆä¸º Rust-AI å¼€å‘çš„è¡Œå®¶é‡Œæ‰‹ï¼"
date: 2025-07-22T10:20:00Z
image: "https://static-rs.bifuba.com/images/250804/pexels-nexionly-4116411.jpg"
categories: [ "Rust","Cargo","Siumai" ]
authors: [ "houseme" ]
tags: [ "rust","cargo","Cargo.toml","Siumai","LLM","AI","OpenAI","Anthropic","Ollama","Google Gemini" ]
keywords: "rust,cargo,Cargo.toml,Siumai,LLM,AI,OpenAI,Anthropic,Ollama,Google Gemini"
draft: false
---

## å¼•è¨€ï¼šç”¨ Siumai ç‚¹ç‡ƒ Rust ä¸ AI çš„åŒ–å­¦ååº”

åœ¨ Rust çš„å¼ºç±»å‹å®‰å…¨ä¸é«˜æ€§èƒ½ç¼–ç¨‹ä¸–ç•Œä¸­ï¼ŒSiumaiï¼ˆçƒ§å–ï¼‰å¦‚åŒä¸€é“ç¾å‘³ä½³è‚´ï¼Œå°†å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ API ç»Ÿä¸€ä¸ºä¼˜é›…ã€æ¨¡å—åŒ–çš„æ¥å£ï¼Œä¸ºå¼€å‘è€…æä¾›äº†æ— ä¸ä¼¦æ¯”çš„å¼€å‘ä½“éªŒã€‚æ— è®ºæ˜¯è°ƒç”¨ OpenAI çš„ GPT-4oã€Anthropic çš„ Claudeï¼Œè¿˜æ˜¯æœ¬åœ°è¿è¡Œçš„ Ollama æ¨¡å‹ï¼ŒSiumai é€šè¿‡å…¶èƒ½åŠ›åˆ†å±‚è®¾è®¡ã€ç±»å‹å®‰å…¨å‚æ•°å¤„ç†å’Œå¼‚æ­¥æµå¼æ”¯æŒï¼Œæå¤§ç®€åŒ–äº† AI åº”ç”¨çš„å¼€å‘æµç¨‹ã€‚

æœ¬æ–‡å°†æ·±å…¥æ¢è®¨ Siumai åœ¨å®é™…å¼€å‘ä¸­çš„æœ€ä½³å®è·µï¼Œè¦†ç›–ä»åŸºç¡€å¯¹è¯åˆ°å¤æ‚å·¥å…·è°ƒç”¨ã€æµå¼å¤„ç†ä¼˜åŒ–ä»¥åŠæœ¬åœ°æ¨¡å‹éƒ¨ç½²çš„åœºæ™¯ã€‚æˆ‘ä»¬å°†ç»“åˆç†è®ºåˆ†æä¸å®æˆ˜ä»£ç ï¼Œç”±æµ…å…¥æ·±åœ°å±•ç¤ºå¦‚ä½•åˆ©ç”¨ Siumai æ„å»ºé«˜æ•ˆã€å¥å£®çš„ AI åº”ç”¨ï¼ŒåŠ©ä½ æˆä¸º Rust-AI å¼€å‘çš„è¡Œå®¶é‡Œæ‰‹ï¼

## ç›®æ ‡è¯»è€…

- å¯¹ Rust å’Œ Siumai æœ‰åŸºç¡€äº†è§£çš„å¼€å‘è€…
- å¸Œæœ›åœ¨å®é™…é¡¹ç›®ä¸­é«˜æ•ˆé›†æˆ AI åŠŸèƒ½çš„å·¥ç¨‹å¸ˆ
- è¿½æ±‚ä»£ç ä¼˜é›…ã€æ€§èƒ½ä¼˜åŒ–çš„ Rust çˆ±å¥½è€…

## ç†è®ºåŸºç¡€ï¼šSiumai çš„æœ€ä½³å®è·µåŸåˆ™

### 1. ç»Ÿä¸€æ¥å£ï¼Œè·¨æä¾›å•†å¤ç”¨

Siumai çš„`Siumai::builder()`æä¾›ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒ OpenAIã€Anthropicã€Ollama ç­‰å¤šä¸ªæä¾›å•†ã€‚æœ€ä½³å®è·µæ˜¯ä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼Œå‡å°‘å¯¹ç‰¹å®šæä¾›å•†çš„ä¾èµ–ï¼Œæå‡ä»£ç å¯ç§»æ¤æ€§ã€‚

### 2. èƒ½åŠ›åˆ†å±‚ï¼Œæ¨¡å—åŒ–è®¾è®¡

Siumai é€šè¿‡`ChatCapability`ã€`ToolCapability`ç­‰ trait å®ç°åŠŸèƒ½æ¨¡å—åŒ–ã€‚å¼€å‘è€…åº”æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„èƒ½åŠ›æ¥å£ï¼Œé¿å…å¼•å…¥ä¸å¿…è¦çš„å¤æ‚æ€§ã€‚

### 3. ç±»å‹å®‰å…¨ä¸å‚æ•°ä¼˜åŒ–

åˆ©ç”¨ Rust çš„ç±»å‹ç³»ç»Ÿå’Œ`EnhancedParameterValidator`ï¼Œåœ¨ç¼–è¯‘æœŸéªŒè¯å‚æ•°ï¼Œå¹¶æ ¹æ®æä¾›å•†ä¼˜åŒ–é…ç½®ï¼Œé™ä½è¿è¡Œæ—¶é”™è¯¯é£é™©ã€‚

### 4. å¼‚æ­¥ä¸æµå¼å¤„ç†

åŸºäº Tokio çš„å¼‚æ­¥æ”¯æŒï¼ŒSiumai é€‚åˆé«˜å¹¶å‘åœºæ™¯ã€‚æµå¼å¤„ç†ï¼ˆ`chat_stream`ï¼‰æ˜¯å®æ—¶åº”ç”¨çš„é¦–é€‰ï¼Œåº”ä¼˜åŒ–æµå¤„ç†é€»è¾‘ä»¥æå‡ç”¨æˆ·ä½“éªŒã€‚

### 5. é”™è¯¯å¤„ç†ä¸é‡è¯•æœºåˆ¶

é€šè¿‡`RetryExecutor`å’Œ`ErrorClassifier`ï¼Œå®ç°æ™ºèƒ½é‡è¯•ä¸é”™è¯¯æ¢å¤ï¼Œç¡®ä¿åº”ç”¨åœ¨ç½‘ç»œä¸ç¨³å®šæˆ– API é™åˆ¶ä¸‹çš„å¥å£®æ€§ã€‚

### 6. æœ¬åœ°æ¨¡å‹ä¼˜å…ˆ

åœ¨éšç§æ•æ„Ÿæˆ–èµ„æºå—é™åœºæ™¯ä¸‹ï¼Œä½¿ç”¨ Ollama è¿è¡Œæœ¬åœ°æ¨¡å‹ï¼Œç»“åˆ Siumai çš„é…ç½®é€‰é¡¹ï¼ˆå¦‚`num_ctx`ã€`num_gpu`ï¼‰ä¼˜åŒ–æ€§èƒ½ã€‚

## ç¯å¢ƒå‡†å¤‡

### 1. å®‰è£… Rust

ç¡®ä¿ Rust å¼€å‘ç¯å¢ƒå·²é…ç½®ï¼š

```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

### 2. åˆ›å»ºæ–°é¡¹ç›®

```bash
cargo new siumai-best-practices
cd siumai-best-practices
```

### 3. é…ç½® Cargo.toml

ç¼–è¾‘`Cargo.toml`ï¼Œæ·»åŠ ä¾èµ–å¹¶è®¾ç½®`edition = "2024"`ï¼š

```toml
[package]
name = "siumai-best-practices"
version = "0.1.0"
edition = "2024"

[dependencies]
siumai = "0.7.0"
tokio = { version = "1.0", features = ["full"] }
serde_json = "1.0"
futures = "0.3"
reqwest = { version = "0.11", features = ["json"] }
```

### 4. å‡†å¤‡ API å¯†é’¥ä¸ Ollama

- **OpenAI/Anthropic**ï¼šä»[OpenAI å®˜ç½‘](https://platform.openai.com/ "OpenAIå®˜ç½‘")æˆ–[Anthropic å®˜ç½‘](https://console.anthropic.com/ "Anthropicå®˜ç½‘")è·å– API å¯†é’¥ã€‚
- **Ollama**ï¼šå®‰è£… Ollama å¹¶å¯åŠ¨æœåŠ¡ï¼š
  ```bash
  ollama serve
  ollama pull llama3.2
  ```

## å®æˆ˜åœºæ™¯ï¼šSiumai æœ€ä½³å®è·µ

### åœºæ™¯ 1ï¼šåŸºç¡€å¯¹è¯â€”â€”ç»Ÿä¸€æ¥å£çš„ä¼˜é›…å®ç°

**ç›®æ ‡**ï¼šé€šè¿‡ç»Ÿä¸€æ¥å£è°ƒç”¨ OpenAI çš„ GPT-4oï¼Œå®ç°ç®€æ´çš„å¯¹è¯åŠŸèƒ½ï¼ŒåŒæ—¶ç¡®ä¿ä»£ç å¯ç§»æ¤æ€§ã€‚

**æœ€ä½³å®è·µ**ï¼š

- ä½¿ç”¨`Siumai::builder()`ï¼Œé¿å…ç¡¬ç¼–ç æä¾›å•†ã€‚
- é…ç½®é€šç”¨å‚æ•°ï¼ˆå¦‚`temperature`ã€`max_tokens`ï¼‰ï¼Œä¾¿äºåˆ‡æ¢æä¾›å•†ã€‚
- ä½¿ç”¨`user!`å®ç®€åŒ–æ¶ˆæ¯åˆ›å»ºã€‚

```rust
use siumai::prelude::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // ä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼Œé…ç½® OpenAI
    let client = Siumai::builder()
        .openai()
        .api_key(std::env::var("OPENAI_API_KEY")?)
        .model("gpt-4o")
        .temperature(0.7)
        .max_tokens(500)
        .build()
        .await?;

    let messages = vec![user!("è¯·ç”¨ç®€å•è¯­è¨€è§£é‡ŠåŒºå—é“¾çš„æ ¸å¿ƒæ¦‚å¿µ")];
    let response = client.chat(messages).await?;

    println!("GPT-4o å›ç­”ï¼š{}", response.text().unwrap_or_default());
    Ok(())
}
```

**è¿è¡Œä»£ç **ï¼š

```bash
export OPENAI_API_KEY="your-openai-key"
cargo run --bin basic_chat
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
GPT-4oå›ç­”ï¼šåŒºå—é“¾æ˜¯ä¸€ç§å»ä¸­å¿ƒåŒ–çš„æ•°å­—è´¦æœ¬ï¼Œé€šè¿‡åˆ†å¸ƒå¼ç½‘ç»œè®°å½•äº¤æ˜“ã€‚å®ƒçš„æ ¸å¿ƒæ¦‚å¿µåŒ…æ‹¬ï¼š1. åŒºå—ï¼šå­˜å‚¨äº¤æ˜“æ•°æ®çš„å•å…ƒï¼›2. é“¾ï¼šåŒºå—æŒ‰æ—¶é—´é¡ºåºé“¾æ¥ï¼›3. å»ä¸­å¿ƒåŒ–ï¼šæ²¡æœ‰å•ä¸€æ§åˆ¶ç‚¹ï¼Œæ‰€æœ‰èŠ‚ç‚¹å…±äº«æ•°æ®ï¼›4. åŠ å¯†ï¼šç¡®ä¿æ•°æ®å®‰å…¨å’Œä¸å¯ç¯¡æ”¹ã€‚åŒºå—é“¾å¸¸ç”¨äºåŠ å¯†è´§å¸ã€æ™ºèƒ½åˆçº¦ç­‰åœºæ™¯ã€‚
```

**è§£æ**ï¼š

- ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨ API å¯†é’¥ï¼Œå¢å¼ºå®‰å…¨æ€§ã€‚
- `temperature(0.7)`å’Œ`max_tokens(500)`æ˜¯é€šç”¨å‚æ•°ï¼Œé€‚é…å¤šç§æä¾›å•†ã€‚
- è‹¥éœ€åˆ‡æ¢åˆ° Anthropicï¼Œåªéœ€å°†`.openai()`æ›¿æ¢ä¸º`.anthropic()`ï¼Œå…¶ä½™ä»£ç æ— éœ€ä¿®æ”¹ã€‚

### åœºæ™¯ 2ï¼šæµå¼å¤„ç†â€”â€”å®æ—¶äº¤äº’ä¼˜åŒ–

**ç›®æ ‡**ï¼šå®ç°å®æ—¶å¯¹è¯ï¼Œä¼˜åŒ–æµå¼å¤„ç†æ€§èƒ½ï¼Œé€‚åˆèŠå¤©æœºå™¨äººåœºæ™¯ã€‚

**æœ€ä½³å®è·µ**ï¼š

- ä½¿ç”¨`chat_stream`å¤„ç†æµå¼å“åº”ã€‚
- é€šè¿‡ç¼“å†²åŒºå‡å°‘ I/O æ“ä½œï¼Œæå‡æ€§èƒ½ã€‚
- æ·»åŠ é”™è¯¯å¤„ç†ï¼Œåº”å¯¹æµä¸­æ–­ã€‚

```rust
use siumai::prelude::*;
use futures::StreamExt;
use std::time::Instant;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = Siumai::builder()
        .openai()
        .api_key(std::env::var("OPENAI_API_KEY")?)
        .model("gpt-4o")
        .temperature(0.8)
        .build()
        .await?;

    let messages = vec![user!("å†™ä¸€é¦–å…³äºæœªæ¥çš„äº”è¡Œè¯—")];
    let mut stream = client.chat_stream(messages).await?;

    let start = Instant::now();
    let mut buffer = String::new();

    while let Some(event) = stream.next().await {
        match event {
            Ok(chunk) => {
                if let Some(text) = chunk.text() {
                    buffer.push_str(&text);
                    if buffer.len() > 30 {
                        print!("{}", buffer);
                        buffer.clear();
                    }
                }
            }
            Err(e) => eprintln!("æµé”™è¯¯ï¼š{}", e),
        }
    }
    if !buffer.is_empty() {
        print!("{}", buffer);
    }
    println!("\nè€—æ—¶ï¼š{:?}", start.elapsed());
    Ok(())
}
```

**è¿è¡Œä»£ç **ï¼š

```bash
cargo run --bin stream_chat
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
æœªæ¥å¦‚æ˜Ÿè¾°ï¼Œç®—æ³•ç»˜è“å›¾ï¼Œ
æ™ºèƒ½è¿ä¸‡ç‰©ï¼Œæ¢¦æƒ³è§¦å¤©é™…ï¼Œ
äººæœºå…±åˆ›ä¸–ã€‚
è€—æ—¶ï¼š1.8s
```

**è§£æ**ï¼š

- ç¼“å†²åŒºï¼ˆ`buffer`ï¼‰æ¯ 30 ä¸ªå­—ç¬¦æ‰“å°ä¸€æ¬¡ï¼Œå‡å°‘ I/O å¼€é”€ã€‚
- é”™è¯¯å¤„ç†æ•è·æµä¸­æ–­ï¼Œç¡®ä¿ç¨‹åºå¥å£®æ€§ã€‚
- `Instant`è®°å½•è€—æ—¶ï¼Œæ–¹ä¾¿æ€§èƒ½ç›‘æ§ã€‚

### åœºæ™¯ 3ï¼šæœ¬åœ° Ollama éƒ¨ç½²â€”â€”éšç§ä¸æ€§èƒ½å…¼å¾—

**ç›®æ ‡**ï¼šä½¿ç”¨ Ollama è¿è¡Œ LLaMA3.2 æ¨¡å‹ï¼Œä¼˜åŒ–æœ¬åœ°æ€§èƒ½ï¼Œé€‚åˆéšç§æ•æ„Ÿåœºæ™¯ã€‚

**æœ€ä½³å®è·µ**ï¼š

- é…ç½®`OllamaConfig`ä»¥ä¼˜åŒ–ä¸Šä¸‹æ–‡çª—å£å’Œ GPU ä½¿ç”¨ã€‚
- å¯ç”¨`think`æ¨¡å¼ï¼Œè·å–æ¨¡å‹æ¨ç†è¿‡ç¨‹ã€‚
- ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ç®¡ç†`base_url`ã€‚

```rust
use siumai::prelude::*;
use siumai::providers::ollama::{OllamaClient, OllamaConfig};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let config = OllamaConfig::builder()
        .base_url("http://localhost:11434")
        .model("llama3.2:latest")
        .keep_alive("10m")
        .num_ctx(4096)
        .num_gpu(1)
        .think(true)
        .option("temperature", serde_json::Value::Number(
            serde_json::Number::from_f64(0.7).unwrap()
        ))
        .build()?;

    let client = OllamaClient::new_with_config(config);
    let messages = vec![user!("é€æ­¥è§£é‡Šï¼šå¦‚ä½•ä¼˜åŒ– Rust ç¨‹åºæ€§èƒ½ï¼Ÿ")];
    let response = client.chat(messages).await?;

    if let Some(thinking) = &response.thinking {
        println!("ğŸ§  æ¨ç†è¿‡ç¨‹ï¼š{}", thinking);
    }
    println!("ğŸ“ å›ç­”ï¼š{}", response.text().unwrap_or_default());
    Ok(())
}
```

**è¿è¡Œä»£ç **ï¼š

```bash
ollama serve
cargo run --bin ollama_local
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
ğŸ§  æ¨ç†è¿‡ç¨‹ï¼š1. åˆ†æRustæ€§èƒ½ç“¶é¢ˆï¼šCPUã€å†…å­˜ã€I/Oï¼›2. ä¼˜åŒ–ç­–ç•¥ï¼šå‡å°‘å…‹éš†ã€ä½¿ç”¨å¼•ç”¨ã€å¼‚æ­¥ç¼–ç¨‹ï¼›3. å·¥å…·ï¼šprofilingã€cargo bench...
ğŸ“ å›ç­”ï¼šä¼˜åŒ–Rustç¨‹åºæ€§èƒ½çš„å…³é”®åŒ…æ‹¬ï¼š1. ä½¿ç”¨`cargo bench`è¿›è¡Œæ€§èƒ½åˆ†æï¼›2. é¿å…ä¸å¿…è¦çš„`clone`ï¼Œä¼˜å…ˆä½¿ç”¨å€Ÿç”¨ï¼›3. åˆ©ç”¨Tokioå®ç°å¼‚æ­¥I/Oï¼›4. é€‰æ‹©åˆé€‚çš„é›†åˆç±»å‹ï¼Œå¦‚`Vec`æˆ–`BTreeMap`...
```

**è§£æ**ï¼š

- `num_ctx(4096)`æ”¯æŒæ›´é•¿çš„ä¸Šä¸‹æ–‡ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡ã€‚
- `think(true)`æä¾›æ¨ç†è¿‡ç¨‹ï¼Œå¢å¼ºç»“æœå¯è§£é‡Šæ€§ã€‚
- æœ¬åœ°éƒ¨ç½²é¿å…äº†äº‘ç«¯ API çš„éšç§é£é™©ã€‚

### åœºæ™¯ 4ï¼šå·¥å…·è°ƒç”¨â€”â€”è‡ªåŠ¨åŒ–å·¥ä½œæµ

**ç›®æ ‡**ï¼šé€šè¿‡å·¥å…·è°ƒç”¨å®ç°å¤æ‚ä»»åŠ¡è‡ªåŠ¨åŒ–ï¼Œå¦‚æ•°å­¦è®¡ç®—æˆ–å¤–éƒ¨ API æŸ¥è¯¢ã€‚

**æœ€ä½³å®è·µ**ï¼š

- å®šä¹‰æ¸…æ™°çš„å·¥å…· schemaï¼Œä½¿ç”¨`serde_json`æ„é€ å‚æ•°ã€‚
- å¤„ç†å¤šè½®å¯¹è¯ï¼Œç¡®ä¿å·¥å…·ç»“æœæ­£ç¡®åé¦ˆã€‚
- ä½¿ç”¨`RetryExecutor`å¢å¼ºå¯é æ€§ã€‚

```rust
use siumai::prelude::*;
use siumai::retry::{RetryPolicy, RetryExecutor};
use siumai::types::{Tool, ToolResult};
use serde_json::json;
use std::time::Duration;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let client = Siumai::builder()
        .openai()
        .api_key(std::env::var("OPENAI_API_KEY")?)
        .model("gpt-4o")
        .build()
        .await?;

    let calc_tool = Tool {
        name: "calculate".to_string(),
        description: "Perform mathematical calculations".to_string(),
        parameters: json!({
            "type": "object",
            "properties": {
                "expression": {
                    "type": "string",
                    "description": "Mathematical expression to evaluate"
                }
            },
            "required": ["expression"]
        }),
    };

    let messages = vec![user!("è®¡ç®— (50 * 3 + 20) / 2")];
    let policy = RetryPolicy::new()
        .with_max_attempts(3)
        .with_initial_delay(Duration::from_millis(500))
        .with_backoff_multiplier(2.0);

    let executor = RetryExecutor::new(policy);
    let response = executor.execute(|| async {
        client.chat_with_tools(messages.clone(), Some(vec![calc_tool.clone()])).await
    }).await?;

    if let Some(tool_calls) = response.tool_calls() {
        let mut tool_results = vec![];
        for call in tool_calls {
            if call.function.name == "calculate" {
                let expr = call.function.arguments["expression"].as_str().unwrap();
                let result = if expr == "(50 * 3 + 20) / 2" { "85".to_string() } else { "Error".to_string() };
                tool_results.push(ToolResult {
                    call_id: call.id,
                    content: result,
                });
            }
        }
        let follow_up = client.chat_with_tools(vec![response.into(), tool_results.into()], None).await?;
        println!("æœ€ç»ˆç»“æœï¼š{}", follow_up.text().unwrap_or_default());
    }

    Ok(())
}
```

**è¿è¡Œä»£ç **ï¼š

```bash
cargo run --bin tool_call
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
æœ€ç»ˆç»“æœï¼š(50 * 3 + 20) / 2 = 85
```

**è§£æ**ï¼š

- å·¥å…· schema ä½¿ç”¨ JSON å®šä¹‰ï¼Œç¡®ä¿ä¸æ¨¡å‹å…¼å®¹ã€‚
- `RetryExecutor`ç¡®ä¿å·¥å…·è°ƒç”¨åœ¨ç½‘ç»œä¸ç¨³å®šæ—¶ä»å¯é ã€‚
- å¤šè½®å¯¹è¯é€šè¿‡å°†å·¥å…·ç»“æœåé¦ˆç»™æ¨¡å‹å®ç°è‡ªåŠ¨åŒ–ã€‚

### åœºæ™¯ 5ï¼šå‚æ•°ä¼˜åŒ–ä¸é”™è¯¯å¤„ç†

**ç›®æ ‡**ï¼šé€šè¿‡å‚æ•°éªŒè¯å’Œæ™ºèƒ½é”™è¯¯å¤„ç†æå‡åº”ç”¨å¥å£®æ€§ã€‚

**æœ€ä½³å®è·µ**ï¼š

- ä½¿ç”¨`EnhancedParameterValidator`ä¼˜åŒ–å‚æ•°ã€‚
- ç»“åˆ`ErrorClassifier`æä¾›è¯¦ç»†é”™è¯¯åˆ†æã€‚
- é…ç½®è‡ªå®šä¹‰ HTTP å®¢æˆ·ç«¯ï¼Œä¼˜åŒ–ç½‘ç»œæ€§èƒ½ã€‚

```rust
use siumai::prelude::*;
use siumai::params::EnhancedParameterValidator;
use siumai::error_handling::{ErrorClassifier, ErrorContext};
use std::time::Duration;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let custom_client = reqwest::Client::builder()
        .timeout(Duration::from_secs(30))
        .pool_max_idle_per_host(5)
        .build()?;

    let client = Siumai::builder()
        .openai()
        .api_key(std::env::var("OPENAI_API_KEY")?)
        .model("gpt-4o")
        .http_client(custom_client)
        .build()
        .await?;

    let mut params = CommonParams {
        model: "gpt-4o".to_string(),
        temperature: Some(1.2),
        max_tokens: Some(4000),
        ..Default::default()
    };

    let optimization_report = EnhancedParameterValidator::optimize_for_provider(
        &mut params,
        &ProviderType::OpenAi,
    );
    println!("ä¼˜åŒ–æŠ¥å‘Šï¼š{:?}", optimization_report);

    let messages = vec![user!("ç”Ÿæˆä¸€ç¯‡å…³äº AI ä¼¦ç†çš„æ–‡ç« ")];
    match client.chat(messages).await {
        Ok(response) => println!("ç»“æœï¼š{}", response.text().unwrap_or_default()),
        Err(error) => {
            let context = ErrorContext::default();
            let classified = ErrorClassifier::classify(&error, context);
            println!("é”™è¯¯ç±»å‹ï¼š{:?}", classified.category);
            println!("ä¸¥é‡æ€§ï¼š{:?}", classified.severity);
            println!("æ¢å¤å»ºè®®ï¼š{:?}", classified.recovery_suggestions);
        }
    }

    Ok(())
}
```

**è¿è¡Œä»£ç **ï¼š

```bash
cargo run --bin param_error
```

**è¾“å‡ºç¤ºä¾‹**ï¼š

```
ä¼˜åŒ–æŠ¥å‘Šï¼šOptimizationReport { changes: ["temperature reduced to 1.0 for stability", "max_tokens capped at 2000 for cost efficiency"] }
ç»“æœï¼šAIä¼¦ç†æ˜¯æŠ€æœ¯å‘å±•çš„å…³é”®è®®é¢˜ï¼Œæ¶‰åŠéšç§ã€å…¬å¹³å’Œé€æ˜æ€§ã€‚å¼€å‘è€…éœ€ç¡®ä¿AIç³»ç»Ÿä¸å¼ºåŒ–åè§ï¼ŒåŒæ—¶ä¿æŠ¤ç”¨æˆ·æ•°æ®...
```

**è§£æ**ï¼š

- `EnhancedParameterValidator`å°†`temperature`ä» 1.2 é™è‡³ 1.0ï¼Œ`max_tokens`ä» 4000 é™è‡³ 2000ï¼Œæå‡ç¨³å®šæ€§å’Œæˆæœ¬æ•ˆç‡ã€‚
- `ErrorClassifier`æä¾›è¯¦ç»†é”™è¯¯åˆ†æï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒã€‚
- è‡ªå®šä¹‰ HTTP å®¢æˆ·ç«¯é€šè¿‡è¿æ¥æ± ä¼˜åŒ–ç½‘ç»œæ€§èƒ½ã€‚

## å‚è€ƒèµ„æ–™

1. **Siumai å®˜æ–¹æ–‡æ¡£**ï¼šhttps://crates.io/crates/siumai
2. **GitHub ä»“åº“**ï¼šhttps://github.com/YumchaLabs/siumai
3. **Rust 2024 Edition**ï¼šhttps://doc.rust-lang.org/stable/edition-guide/rust-2024/
4. **Tokio å¼‚æ­¥ç¼–ç¨‹**ï¼šhttps://tokio.rs/
5. **OpenAI API**ï¼šhttps://platform.openai.com/docs/
6. **Anthropic API**ï¼šhttps://docs.anthropic.com/
7. **Ollama æ–‡æ¡£**ï¼šhttps://ollama.ai/

## æ€»ç»“

Siumai çš„æœ€ä½³å®è·µæ¶µç›–äº†ç»Ÿä¸€æ¥å£ã€æµå¼å¤„ç†ã€æœ¬åœ°æ¨¡å‹éƒ¨ç½²ã€å·¥å…·è°ƒç”¨å’Œå‚æ•°ä¼˜åŒ–ç­‰åœºæ™¯ã€‚é€šè¿‡æ¨¡å—åŒ–è®¾è®¡ã€ç±»å‹å®‰å…¨å’Œå¼‚æ­¥æ”¯æŒï¼ŒSiumai ä¸º Rust å¼€å‘è€…æä¾›äº†æ„å»ºé«˜æ•ˆ AI åº”ç”¨çš„åšå®åŸºç¡€ã€‚æœ¬æŒ‡å—é€šè¿‡ç†è®ºä¸å®æˆ˜ç»“åˆï¼Œå±•ç¤ºäº†å¦‚ä½•åœ¨å®é™…é¡¹ç›®ä¸­åº”ç”¨è¿™äº›å®è·µã€‚å¸Œæœ›ä½ èƒ½å°† Siumai èå…¥ä½ çš„å¼€å‘æµç¨‹ï¼Œåˆ›é€ å‡ºä¼˜é›…è€Œå¼ºå¤§çš„ AI è§£å†³æ–¹æ¡ˆï¼

**ä¸‹ä¸€æ­¥**ï¼š

- æ¢ç´¢ Siumai çš„è‡ªå®šä¹‰æä¾›å•†åŠŸèƒ½ï¼Œé€‚é…æ–°å…´ AI æ¨¡å‹ã€‚
- ä¼˜åŒ–æµå¼å¤„ç†é€»è¾‘ï¼Œå¼€å‘å®æ—¶äº¤äº’åº”ç”¨ã€‚
- åŠ å…¥ Siumai ç¤¾åŒºï¼Œåˆ†äº«ä½ çš„æœ€ä½³å®è·µï¼

Made with â¤ï¸ by YumchaLabs & the Rust Community
